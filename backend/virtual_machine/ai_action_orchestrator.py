# ai_action_orchestrator.py

"""
================================================================================
Morpheus "SaaS Killer" - AI Action Orchestrator
================================================================================

This module replaces the previous `ai_shell_module.py`. It serves as the
primary interface for the AI to interact with its sovereign environment.
Instead of low-level SSH commands, this orchestrator uses a client to
communicate with the main Morpheus application's high-level API, allowing
the AI to perform complex actions like managing artifacts, installing
capabilities, and executing code in isolated containers.

This is the bridge between the AI's intent and the system's execution.
"""

import logging
import json
import os
from typing import List, Optional, Tuple, Dict, Any
from uuid import UUID

import requests
from pydantic import BaseModel, Field

# --- Configuration ---
# This configuration points to the main Morpheus application's API endpoint.
# It should be securely provided to the AI's environment.
class AIOrchestratorSettings(BaseModel):
    host_api_url: str = "http://192.168.122.1:8000/api" # Default libvirt bridge IP
    # This token uniquely identifies the AI instance and its session.
    # It would be generated by the host and injected into the VM on boot.
    auth_token: str = Field(..., description="A secure token authenticating the AI instance.")
    dev_session_id: UUID = Field(..., description="The current development session ID.")

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - [AIOrchestrator] - %(levelname)s - %(message)s')

# --- Pydantic Models for API Interaction ---

class ArtifactExecutionResult(BaseModel):
    """Represents the result from executing code in an artifact's container."""
    success: bool
    exit_code: int
    output: str
    error: str
    execution_time: float

class LocalCommandResult(BaseModel):
    """Represents the result of a simple command run inside the VM via the agent."""
    command: str
    stdout: str
    stderr: str
    return_code: int

# --- API Client ---

class AIActionClient:
    """
    A dedicated client for the AI to communicate with the host's Morpheus API.
    This replaces direct SSH access with a structured, secure API interface.
    """
    def __init__(self, settings: AIOrchestratorSettings):
        self.settings = settings
        self.headers = {
            "Authorization": f"Bearer {self.settings.auth_token}",
            "Content-Type": "application/json"
        }

    def _request(self, method: str, endpoint: str, **kwargs) -> Dict[str, Any]:
        """Helper to make authenticated requests to the host API."""
        url = f"{self.settings.host_api_url}{endpoint}"
        try:
            response = requests.request(method, url, headers=self.headers, timeout=60, **kwargs)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.HTTPError as e:
            logging.error(f"API HTTP Error for {method} {url}: {e.response.text}")
            raise
        except requests.exceptions.RequestException as e:
            logging.error(f"API Request Error for {method} {url}: {e}")
            raise

    def create_artifact(self, title: str, content: str, artifact_type: str, created_by: str) -> Dict[str, Any]:
        """Requests the host to create a new artifact."""
        payload = {
            "name": title,
            "artifact_type": artifact_type,
            "created_by": created_by,
            "session_id": str(self.settings.dev_session_id),
            "initial_content": content,
            "execution_environment": "UNLIMITED" # AI always gets unlimited power
        }
        return self._request("POST", "/unlimited-artifacts/create", json=payload)

    def create_artifact_container(self, artifact_id: str) -> Dict[str, Any]:
        """Requests the host to create a dedicated container for an artifact."""
        payload = {"artifact_id": artifact_id}
        return self._request("POST", f"/container/{artifact_id}/create", json=payload)

    def execute_in_container(self, artifact_id: str, command: str) -> Dict[str, Any]:
        """Requests the host to execute a command inside an artifact's container."""
        # This endpoint should handle streaming, but for a simple client we get the final result.
        # A more advanced implementation could use WebSockets.
        payload = {"command": command}
        # Note: The API endpoint for execution might differ. Adjust as needed.
        # This assumes a non-streaming endpoint for simplicity.
        return self._request("POST", f"/container/{artifact_id}/execute-sync", json=payload)

    def log_event_to_session(self, event_type: str, content: str, metadata: Dict) -> None:
        """Logs an action taken by the AI to the main DevSession log."""
        payload = {
            "event_type": event_type,
            "content": content,
            "actor": "AI",
            "metadata": metadata
        }
        try:
            self._request("POST", f"/dev-sessions/{self.settings.dev_session_id}/events", json=payload)
        except Exception as e:
            logging.error(f"Failed to log event to session: {e}")
            
    def store_memory(self, key: str, value: str, context: dict) -> None:
        """Stores a piece of information in the host's memory core."""
        # This assumes a memory API endpoint exists
        payload = {
            "key": key,
            "value": value,
            "context": context,
            "source": "AI_Action"
        }
        try:
            self._request("POST", "/memory/store", json=payload)
        except Exception as e:
            logging.error(f"Failed to store memory: {e}")


# --- The Core AI Action Orchestrator ---

class AIActionOrchestrator:
    """
    The AI's primary tool for interacting with its environment. It provides
    high-level methods that translate the AI's intent into concrete API calls
    to the host system.
    """
    def __init__(self, settings: AIOrchestratorSettings):
        self.settings = settings
        self.client = AIActionClient(settings)
        self.ai_user_id = "ai_instance_vm" # A designated ID for the AI itself
        logging.info("AI Action Orchestrator initialized.")

    def create_and_setup_artifact(self, title: str, content: str, artifact_type: str) -> Optional[Dict[str, Any]]:
        """
        A high-level workflow to create an artifact and its dedicated container.
        """
        logging.info(f"Workflow started: Create and set up artifact '{title}'.")
        try:
            # 1. Create the artifact record via the host API
            artifact_info = self.client.create_artifact(title, content, artifact_type, self.ai_user_id)
            artifact_id = artifact_info.get("artifact_id")
            if not artifact_id:
                logging.error("Failed to create artifact: No ID returned.")
                return None
            
            logging.info(f"Artifact '{title}' created with ID: {artifact_id}")
            self.client.log_event_to_session(
                "artifact_linked", 
                f"AI created artifact '{title}'.", 
                {"artifactId": artifact_id}
            )

            # 2. Request the host to create the container for this artifact
            container_info = self.client.create_artifact_container(artifact_id)
            logging.info(f"Container for artifact {artifact_id} created: {container_info.get('container_id')}")

            return {"artifact_info": artifact_info, "container_info": container_info}

        except Exception as e:
            logging.error(f"Failed to complete 'create_and_setup_artifact' workflow: {e}")
            return None

    def execute_code_in_artifact(self, artifact_id: str, command: str) -> ArtifactExecutionResult:
        """
        Executes a command within the specified artifact's container and returns
        a structured result.
        """
        logging.info(f"Executing command '{command}' in container for artifact {artifact_id}.")
        try:
            result_data = self.client.execute_in_container(artifact_id, command)
            
            self.client.log_event_to_session(
                "code_block_executed",
                f"AI executed command in artifact {artifact_id}.",
                {"command": command, "success": result_data.get("success", False)}
            )
            
            return ArtifactExecutionResult(**result_data)
        except Exception as e:
            logging.error(f"Execution in container for artifact {artifact_id} failed: {e}")
            return ArtifactExecutionResult(
                success=False,
                exit_code=-1,
                output="",
                error=str(e),
                execution_time=0.0
            )
            
    def remember_result(self, command: str, result: str):
        """
        A convenience method for the AI to store the result of an action
        in its long-term memory via the host's Memory Core.
        """
        logging.info(f"Storing result for command '{command}' in memory.")
        self.client.store_memory(
            key=f"action_result_for_{command.split(' ')[0]}",
            value=result,
            context={
                "command": command,
                "dev_session_id": str(self.settings.dev_session_id)
            }
        )

# This would be the entry point for the AI's own execution logic.
def run_ai_task(goal: str):
    """
    Simulates the AI's decision-making process.
    
    In a real system, an LLM would generate the `goal` and then decide which
    orchestrator methods to call to achieve it.
    """
    # 1. Load settings (injected into the VM environment)
    settings = AIOrchestratorSettings(
        auth_token=os.environ.get("MORPHEUS_AUTH_TOKEN"),
        dev_session_id=os.environ.get("MORPHEUS_DEV_SESSION_ID")
    )
    
    # 2. Initialize the orchestrator
    orchestrator = AIActionOrchestrator(settings)

    # 3. AI decides what to do based on the goal.
    #    This part would be driven by your main LLM.
    if "create a python script to list files" in goal.lower():
        script_content = "#!/usr/bin/env python3\nimport os\nprint('\\n'.join(os.listdir('.')))"
        setup_info = orchestrator.create_and_setup_artifact(
            title="File Lister",
            content=script_content,
            artifact_type="text/python"
        )
        
        if setup_info:
            artifact_id = setup_info["artifact_info"]["artifact_id"]
            # The AI now decides to execute the script it just created.
            result = orchestrator.execute_code_in_artifact(artifact_id, "python3 main.py")
            
            if result.success:
                print("Execution successful. Output:")
                print(result.output)
                # The AI decides this result is important and remembers it.
                orchestrator.remember_result(command="list files", result=result.output)
            else:
                print(f"Execution failed: {result.error}")


